{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f201c455",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22306a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_AGENTS = [\n",
    "    \"Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; AcooBrowser; .NET CLR 1.1.4322; .NET CLR 2.0.50727)\",\n",
    "    \"Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 6.0; Acoo Browser; SLCC1; .NET CLR 2.0.50727; Media Center PC 5.0; .NET CLR 3.0.04506)\",\n",
    "    \"Mozilla/4.0 (compatible; MSIE 7.0; AOL 9.5; AOLBuild 4337.35; Windows NT 5.1; .NET CLR 1.1.4322; .NET CLR 2.0.50727)\",\n",
    "    \"Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Win64; x64; Trident/5.0; .NET CLR 3.5.30729; .NET CLR 3.0.30729; .NET CLR 2.0.50727; Media Center PC 6.0)\",\n",
    "    \"Mozilla/5.0 (compatible; MSIE 8.0; Windows NT 6.0; Trident/4.0; WOW64; Trident/4.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; .NET CLR 1.0.3705; .NET CLR 1.1.4322)\",\n",
    "    \"Mozilla/4.0 (compatible; MSIE 7.0b; Windows NT 5.2; .NET CLR 1.1.4322; .NET CLR 2.0.50727; InfoPath.2; .NET CLR 3.0.04506.30)\",\n",
    "    \"Mozilla/5.0 (Windows; U; Windows NT 5.1; zh-CN) AppleWebKit/523.15 (KHTML, like Gecko, Safari/419.3) Arora/0.3 (Change: 287 c9dfb30)\",\n",
    "    \"Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.8.1.2pre) Gecko/20070215 K-Ninja/2.1.1\",\n",
    "    \"Mozilla/5.0 (Windows; U; Windows NT 5.1; zh-CN; rv:1.9) Gecko/20080705 Firefox/3.0 Kapiko/3.0\",\n",
    "    \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.11 (KHTML, like Gecko) Chrome/17.0.963.56 Safari/535.11\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_7_3) AppleWebKit/535.20 (KHTML, like Gecko) Chrome/19.0.1036.7 Safari/535.20\",\n",
    "    \"Opera/9.80 (Macintosh; Intel Mac OS X 10.6.8; U; fr) Presto/2.9.168 Version/11.52\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0257e0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#设置北京各区域对应的网页url\n",
    "region = {\n",
    "    'dongcheng': 'dongcheng/',\n",
    "    'xicheng': 'xicheng/',\n",
    "    'chaoyang': 'chaoyang/',\n",
    "    'haidian': 'haidian/',\n",
    "    'fengtai': 'fengtai/',\n",
    "    'shijingshan': 'shijingshan/',\n",
    "    'tongzhou': 'tongzhou/',\n",
    "    'changping': 'changping/',\n",
    "    'daxing': 'daxing/',\n",
    "    'yizhuangkaifaqu': 'yizhuangkaifaqu/',\n",
    "    'shunyi': 'shunyi/',\n",
    "    'mentougou': 'mentougou/',\n",
    "    'fangshan': 'fangshan/',\n",
    "    'pinggu': 'pinggu/',\n",
    "    'huairou': 'huairou/',\n",
    "    'miyun': 'miyun/',\n",
    "    'yanqing': 'yanqing/',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "358f8f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#随机取user-agents\n",
    "headers = {\"User-Agent\": random.choice(USER_AGENTS)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1623e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spider(regions):\n",
    "    main_url = 'https://bj.fang.ke.com/loupan/'\n",
    "    for key, values in region.items():\n",
    "        if key == regions:\n",
    "            all_list = []\n",
    "            url = main_url + values\n",
    "            response = requests.get(url, timeout=10, headers=headers)\n",
    "            html = response.content\n",
    "            soup = BeautifulSoup(html, \"lxml\")\n",
    "            #通过得到的结果计算页数，每页10个，并进行四舍五入\n",
    "            if soup.find('span', class_=\"value\") == None: \n",
    "                break\n",
    "            page = round(int(soup.find('span', class_=\"value\").string) / 10)\n",
    "            for i in range(1, page + 1):\n",
    "                sleep(1.7)\n",
    "                page_url = main_url + values + f'pg{i}'\n",
    "                response = requests.get(page_url, timeout=10, headers=headers)\n",
    "                html = response.content\n",
    "                soup = BeautifulSoup(html, \"lxml\")\n",
    "                #发现网页在到达50多页的时候不会出现数据，防报错\n",
    "                try:\n",
    "                    house_elements = soup.find_all('li', class_=\"resblock-list post_ulog_exposure_scroll has-results\")\n",
    "                    pass\n",
    "                    for house_elem in house_elements:\n",
    "                        #房价\n",
    "                        price = house_elem.find('span', class_=\"number\")\n",
    "                        #提取是否存在支持vr看房的，支持为1，不支持为0\n",
    "                        try:\n",
    "                            desc = house_elem.find('li', class_=\"icon vr vr-animation-forever\").text\n",
    "                            if desc == \"\":\n",
    "                                have_vr = 1\n",
    "                        except Exception as e:\n",
    "                            have_vr = 0\n",
    "                        #总价的阈值\n",
    "                        total = house_elem.find('div', class_=\"second\")\n",
    "                        #楼盘的名称\n",
    "                        loupan = house_elem.find('a', class_='name')\n",
    "                        # 清理数据，去除空白文本和无用的中文计量单位\n",
    "                        try:\n",
    "                            price = price.text.strip()\n",
    "                        except Exception as e:\n",
    "                            price = '0'\n",
    "                        loupan = loupan.text.replace(\"\\n\", \"\")\n",
    "                        try:\n",
    "                            total = total.text.strip().replace(u'总价', '')\n",
    "                            total = total.replace(u'/套起', '').replace('(万/套)', '')\n",
    "                        except Exception as e:\n",
    "                            total = '0'\n",
    "                        #数据装入列表\n",
    "                        data = loupan, price, total, have_vr\n",
    "                        all_list.append(data)\n",
    "                except:\n",
    "                    break\n",
    "            #通过pandas保存为csv文件\n",
    "            df = pd.DataFrame(all_list)\n",
    "            df.to_csv(f\"{key}.csv\", index=False,encoding=\"utf_8_sig\")\n",
    "            print(f\"{key}.csv保存完毕\")\n",
    "        else:\n",
    "            if regions == 'all':\n",
    "                all_list = []\n",
    "                url = main_url + values\n",
    "                response = requests.get(url, timeout=10, headers=headers)\n",
    "                html = response.content\n",
    "                soup = BeautifulSoup(html, \"lxml\")\n",
    "                if soup.find('span', class_=\"value\") == None: \n",
    "                    break\n",
    "                page = round(int(soup.find('span', class_=\"value\").string) / 10)\n",
    "                for i in range(1, page + 1):\n",
    "                    sleep(1.7)\n",
    "                    page_url = main_url + values + f'pg{i}'\n",
    "                    response = requests.get(page_url, timeout=10, headers=headers)\n",
    "                    html = response.content\n",
    "                    soup = BeautifulSoup(html, \"lxml\")\n",
    "                    try:\n",
    "                        house_elements = soup.find_all('li',\n",
    "                                                       class_=\"resblock-list post_ulog_exposure_scroll has-results\")\n",
    "                        pass\n",
    "                        for house_elem in house_elements:\n",
    "                            price = house_elem.find('span', class_=\"number\")\n",
    "                            try:\n",
    "                                desc = house_elem.find('li', class_=\"icon vr vr-animation-forever\").text\n",
    "                                if desc == \"\":\n",
    "                                    have_vr = 1\n",
    "                            except Exception as e:\n",
    "                                have_vr = 0\n",
    "                            total = house_elem.find('div', class_=\"second\")\n",
    "                            loupan = house_elem.find('a', class_='name')\n",
    "                            # 继续清理数据\n",
    "                            try:\n",
    "                                price = price.text.strip()\n",
    "                            except Exception as e:\n",
    "                                price = '0'\n",
    "                            loupan = loupan.text.replace(\"\\n\", \"\")\n",
    "                            try:\n",
    "                                total = total.text.strip().replace(u'总价', '')\n",
    "                                total = total.replace(u'/套起', '').replace('(万/套)', '')\n",
    "                            except Exception as e:\n",
    "                                total = '0'\n",
    "                            data = loupan, price, total, have_vr\n",
    "                            all_list.append(data)\n",
    "                    except:\n",
    "                        break\n",
    "                df = pd.DataFrame(all_list)\n",
    "                df.to_csv(f\"{key}.csv\", index=False, encoding=\"utf_8_sig\")\n",
    "                print(f\"{key}.csv保存完毕\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f7dc9f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dongcheng.csv保存完毕\n",
      "xicheng.csv保存完毕\n",
      "chaoyang.csv保存完毕\n",
      "haidian.csv保存完毕\n",
      "fengtai.csv保存完毕\n",
      "shijingshan.csv保存完毕\n",
      "tongzhou.csv保存完毕\n",
      "changping.csv保存完毕\n",
      "daxing.csv保存完毕\n",
      "yizhuangkaifaqu.csv保存完毕\n",
      "shunyi.csv保存完毕\n",
      "mentougou.csv保存完毕\n",
      "fangshan.csv保存完毕\n",
      "pinggu.csv保存完毕\n",
      "huairou.csv保存完毕\n",
      "miyun.csv保存完毕\n",
      "yanqing.csv保存完毕\n"
     ]
    }
   ],
   "source": [
    "spider('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7b361b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
